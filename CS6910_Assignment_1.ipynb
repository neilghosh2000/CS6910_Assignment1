{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OylGz6A0Dtb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0X8wGjVGJDf",
    "outputId": "e88f7784-747e-45f4-c264-09e72b551668"
   },
   "outputs": [],
   "source": [
    "# the best set of hyperparameters that we get from the sweep\n",
    "default_parameters = dict(\n",
    "    n_layers= 4,\n",
    "    hidden_layer_size= 128,\n",
    "    learn_rate= 1e-3,\n",
    "    batch_size = 16,\n",
    "    epochs=10,\n",
    "    alpha = 0,\n",
    "    optimizer = \"nadam\",\n",
    "    activation = \"relu\",\n",
    "    weight_init = \"random\"\n",
    "    )\n",
    "config = default_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: arneshbose1 (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">astral-blaze-325</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/neilghosh/cs6910_assignment_1\" target=\"_blank\">https://wandb.ai/neilghosh/cs6910_assignment_1</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/neilghosh/cs6910_assignment_1/runs/2yndx8mg\" target=\"_blank\">https://wandb.ai/neilghosh/cs6910_assignment_1/runs/2yndx8mg</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\Arnesh Kumar Bose\\Desktop\\CS6910 Assignments\\wandb\\run-20210313_183718-2yndx8mg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(config= default_parameters,project=\"cs6910_assignment_1\", entity=\"neilghosh\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4imZB0mnKMzw"
   },
   "outputs": [],
   "source": [
    "#import the data\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "#store the image class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-TURP1gZDx19"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one sample image from each class\n",
    "sample_images = []\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(len(class_names)):\n",
    "    sample_images.append(train_labels.tolist().index(i))\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[sample_images[i]], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[sample_images[i]]])\n",
    "    \n",
    "wandb.log({\"sample_images\": plt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U_IQUlNd3RiF"
   },
   "outputs": [],
   "source": [
    "# convert integer to one-hot vector\n",
    "def one_hot_vector(x):\n",
    "    y = np.zeros((x.size, x.max()+1))\n",
    "    y[np.arange(x.size),x] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GhNlOGf1Pzim"
   },
   "outputs": [],
   "source": [
    "def activation_func(z, activation=\"sigmoid\"):\n",
    "    if activation == \"sigmoid\":\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    elif activation == \"softmax\":\n",
    "        z1 = np.exp(z)\n",
    "        z2 = z1.sum(axis=1)\n",
    "        z2 = np.dstack([z2])\n",
    "        return z1/z2\n",
    "    elif activation == \"tanh\":\n",
    "        return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "    elif activation == \"relu\":\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    else:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7GFem9XQSzZ3"
   },
   "outputs": [],
   "source": [
    "def activation_derivative(z, activation=\"sigmoid\"):\n",
    "    if activation == \"sigmoid\":\n",
    "      sig = 1 / (1 + np.exp(-z))\n",
    "      return sig*(1-sig)\n",
    "    elif activation == \"tanh\":\n",
    "      tanh = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "      return 1 - tanh**2\n",
    "    elif activation == \"relu\":\n",
    "      relu = np.maximum(0, z)\n",
    "      relu[relu > 0] = 1\n",
    "      return relu\n",
    "    else:\n",
    "      return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HichVkAxT6jR"
   },
   "outputs": [],
   "source": [
    "# training on the entire data set\n",
    "input_size = train_images.shape[1]*train_images.shape[2]\n",
    "output_size = len(class_names)\n",
    "\n",
    "train_x = train_images.reshape([train_images.shape[0], input_size, 1])/255\n",
    "test_x = test_images.reshape([test_images.shape[0], input_size, 1])/255\n",
    "\n",
    "# shuffle the training data\n",
    "indices = np.arange(train_x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_y = one_hot_vector(train_labels)\n",
    "test_y = one_hot_vector(test_labels)\n",
    "\n",
    "train_x = train_x[indices]\n",
    "train_y = train_y[indices]\n",
    "\n",
    "train_y = np.dstack([train_y])\n",
    "test_y = np.dstack([test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IWsjJKH2WDUP"
   },
   "outputs": [],
   "source": [
    "nn_layers = [{\"input_dim\" : input_size, \"output_dim\" : config.hidden_layer_size, \"activation\" : config.activation}]\n",
    "for i in range(config.n_layers-1):\n",
    "  nn_layers.append({\"input_dim\" : config.hidden_layer_size, \"output_dim\" : config.hidden_layer_size, \"activation\" : config.activation})\n",
    "nn_layers.append({\"input_dim\" : config.hidden_layer_size, \"output_dim\" : output_size, \"activation\" : \"softmax\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hv0LV8sA4IQU",
    "outputId": "01a5cf74-ecae-4369-c311-addfda7389e3"
   },
   "outputs": [],
   "source": [
    "def init_layers(nn_layers, weight_init, seed = 45):\n",
    "    np.random.seed(seed)\n",
    "    weights = {}\n",
    "\n",
    "    for i, layer in enumerate(nn_layers):\n",
    "        layer_no = i + 1\n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "\n",
    "        if weight_init == \"random\":\n",
    "          weights['w' + str(layer_no)] = np.random.randn(layer_output_size, layer_input_size) * 0.1\n",
    "          weights['b' + str(layer_no)] = np.random.randn(layer_output_size, 1) * 0.1\n",
    "        elif weight_init == \"xavier\":\n",
    "          limit = np.sqrt(6/(layer_input_size + layer_output_size))\n",
    "          weights['w' + str(layer_no)] = np.random.uniform(-limit, limit, size=(layer_output_size, layer_input_size))\n",
    "          weights['b' + str(layer_no)] = np.random.uniform(-limit, limit, size=(layer_output_size, 1))\n",
    "        else:\n",
    "          return \"Error - Weight Initialization\"\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pkgqoh355X8-"
   },
   "outputs": [],
   "source": [
    "def forward_prop(train_x, weights, nn_layers):\n",
    "    layer_output = {}\n",
    "    h_curr = train_x\n",
    "\n",
    "    layer_output[\"h0\"] = train_x\n",
    "    layer_output[\"a0\"] = train_x\n",
    "\n",
    "    for i, layer in enumerate(nn_layers):\n",
    "        layer_no = i + 1\n",
    "        h_prev = h_curr\n",
    "\n",
    "        activation = layer[\"activation\"]\n",
    "        w_curr = weights[\"w\" + str(layer_no)]\n",
    "        b_curr = weights[\"b\" + str(layer_no)]\n",
    "\n",
    "        a_curr = np.matmul(w_curr, h_prev) + b_curr\n",
    "        h_curr = activation_func(a_curr, activation)\n",
    "\n",
    "        layer_output[\"a\" + str(layer_no)] = a_curr\n",
    "        layer_output[\"h\" + str(layer_no)] = h_curr\n",
    "\n",
    "    return h_curr, layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zDkhAt5187Ia"
   },
   "outputs": [],
   "source": [
    "# cross entropy loss + regularization\n",
    "\n",
    "def loss_func(y_hat, y, alpha, weights, nn_layers,func='cross_entropy'):\n",
    "    loss = 0\n",
    "    if func=='cross_entropy':\n",
    "        loss = -np.multiply(y, np.log(y_hat)).sum() / len(y_hat)\n",
    "    elif func=='squared_loss':\n",
    "        squared_diff = np.square(y-y_hat)\n",
    "        loss = squared_diff.sum()/(2*len(y_hat))\n",
    "\n",
    "    l2_reg = 0\n",
    "    for i, layer in enumerate(nn_layers):\n",
    "        layer_no = i + 1\n",
    "        l2_reg += np.sum(weights[\"w\" + str(layer_no)] ** 2)\n",
    "\n",
    "    l2_reg = (alpha / 2) * l2_reg / len(y_hat)\n",
    "\n",
    "    return loss + l2_reg\n",
    "\n",
    "# accuracy\n",
    "def accuracy_func(y_hat, train_y):\n",
    "    correct_pred = np.argmax(y_hat, axis = 1) == np.argmax(train_y, axis = 1)\n",
    "    return sum(bool(x) for x in correct_pred)/len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "X4aDXCVWXLdY"
   },
   "outputs": [],
   "source": [
    "def back_prop(y_hat, y, layer_output, weights, nn_layers, alpha, func='cross_entropy'):\n",
    "    gradients = {}\n",
    "    \n",
    "    m = len(y_hat)\n",
    "\n",
    "    da_prev = np.zeros(y_hat.shape)\n",
    "\n",
    "    if func=='cross_entropy':\n",
    "        da_prev = -(y - y_hat)\n",
    "    elif func=='squared_loss':\n",
    "        y_label = np.where(y[:,:,0] == 1)[1]\n",
    "        da_prev = np.zeros(y_hat.shape)\n",
    "        for i in range(m):\n",
    "            y_l_hat = np.ones((y_hat.shape[1],y_hat.shape[2]))*y_hat[:,y_label[i]][i]\n",
    "            da_prev[i] = np.multiply(np.square(y_hat - y)[i], y_l_hat)\n",
    "    else:\n",
    "        da_prev = np.zeros(y_hat.shape)\n",
    "        print(\"Error - wrong loss function\")\n",
    "            \n",
    "    for i, layer in reversed(list(enumerate(nn_layers))):\n",
    "        layer_index = i + 1\n",
    "\n",
    "        da_curr = da_prev\n",
    "\n",
    "        a_prev = layer_output[\"a\" + str(i)]\n",
    "        h_prev = layer_output[\"h\" + str(i)]\n",
    "        dh_prev = np.zeros(h_prev.shape)\n",
    "\n",
    "        a_curr = layer_output[\"a\" + str(layer_index)]\n",
    "        w_curr = weights[\"w\" + str(layer_index)]\n",
    "        b_curr = weights[\"b\" + str(layer_index)]\n",
    "        dw_curr = np.zeros(w_curr.shape)\n",
    "        db_curr = np.zeros(b_curr.shape)\n",
    "\n",
    "        for j in range(m):\n",
    "            dw_curr += np.dot(da_curr[j], h_prev[j].T)\n",
    "            db_curr += da_curr[j]\n",
    "            dh_prev[j] = np.dot(w_curr.T, da_curr[j])\n",
    "\n",
    "        dw_curr += alpha * w_curr\n",
    "\n",
    "        dw_curr /= m\n",
    "        db_curr /= m\n",
    "\n",
    "        if i > 0:\n",
    "            activation = nn_layers[i - 1][\"activation\"]\n",
    "            da_prev = np.multiply(dh_prev, activation_derivative(a_prev, activation))\n",
    "\n",
    "        gradients[\"dw\" + str(layer_index)] = dw_curr\n",
    "        gradients[\"db\" + str(layer_index)] = db_curr\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "48Iavyp6wVzs"
   },
   "outputs": [],
   "source": [
    "def calculate_loss_accuracy(train_x, train_y, test_x, test_y, weights, nn_layers, alpha,func='cross_entropy'):\n",
    "\n",
    "    y_hat, layer_output = forward_prop(train_x, weights, nn_layers)\n",
    "    training_loss = (loss_func(y_hat, train_y, alpha, weights, nn_layers,func))\n",
    "    training_accuracy = (accuracy_func(y_hat, train_y))\n",
    "\n",
    "    y_hat, layer_output = forward_prop(test_x, weights, nn_layers)\n",
    "    test_loss = (loss_func(y_hat, test_y, alpha, weights, nn_layers,func))\n",
    "    test_accuracy = (accuracy_func(y_hat, test_y))\n",
    "\n",
    "    wandb.log({\"train_loss\": training_loss, \"train_accuracy\": training_accuracy, \"test_loss\": test_loss, \"test_accuracy\": test_accuracy})\n",
    "\n",
    "    return training_loss, training_accuracy, test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AgZeiRhf3ikV"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func='cross_entropy'):\n",
    "\n",
    "  training_loss_list = []\n",
    "  training_accuracy_list = []\n",
    "  test_loss_list = []\n",
    "  test_accuracy_list = []\n",
    "\n",
    "  batch_x = np.array(np.array_split(train_x, n_batches))\n",
    "  batch_y = np.array(np.array_split(train_y, n_batches))\n",
    "\n",
    "  for i in range(epochs):\n",
    "    for j in range(n_batches):\n",
    "\n",
    "        y_hat, layer_output = forward_prop(batch_x[j], weights, nn_layers)\n",
    "        gradients = back_prop(y_hat, batch_y[j], layer_output, weights, nn_layers, alpha,func)\n",
    "\n",
    "        for k, layer in enumerate(nn_layers):\n",
    "          weights[\"w\" + str(k+1)] -= eta * gradients[\"dw\" + str(k+1)]\n",
    "          weights[\"b\" + str(k+1)] -= eta * gradients[\"db\" + str(k+1)]\n",
    "\n",
    "    training_loss, training_accuracy, test_loss, test_accuracy = calculate_loss_accuracy(train_x, train_y, test_x, test_y, weights, nn_layers, alpha,func)\n",
    "\n",
    "    training_loss_list.append(training_loss)\n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print((str(i+1)) + \"/\" + str(epochs) + \" epochs completed\")\n",
    "\n",
    "  return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_gd(train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func='cross_entropy'):\n",
    "\n",
    "  training_loss_list = []\n",
    "  training_accuracy_list = []\n",
    "  test_loss_list = []\n",
    "  test_accuracy_list = []\n",
    "\n",
    "  batch_x = np.array(np.array_split(train_x, n_batches))\n",
    "  batch_y = np.array(np.array_split(train_y, n_batches))\n",
    "\n",
    "  prev_weights = {}\n",
    "\n",
    "  gamma = 0.9\n",
    "\n",
    "  for k, layer in enumerate(nn_layers):\n",
    "          prev_weights[\"w\" + str(k+1)] = np.zeros(weights[\"w\" + str(k+1)].shape)\n",
    "          prev_weights[\"b\" + str(k+1)] = np.zeros(weights[\"b\" + str(k+1)].shape)\n",
    "\n",
    "  for i in range(epochs):\n",
    "    for j in range(n_batches):\n",
    "\n",
    "        y_hat, layer_output = forward_prop(batch_x[j], weights, nn_layers)\n",
    "        gradients = back_prop(y_hat, batch_y[j], layer_output, weights, nn_layers, alpha,func)\n",
    "\n",
    "        for k, layer in enumerate(nn_layers):\n",
    "          prev_weights[\"w\" + str(k+1)] = gamma * prev_weights[\"w\" + str(k+1)] + eta * gradients[\"dw\" + str(k+1)]\n",
    "          prev_weights[\"b\" + str(k+1)] = gamma * prev_weights[\"b\" + str(k+1)] + eta * gradients[\"db\" + str(k+1)]\n",
    "\n",
    "          weights[\"w\" + str(k+1)] -= prev_weights[\"w\" + str(k+1)]\n",
    "          weights[\"b\" + str(k+1)] -= prev_weights[\"b\" + str(k+1)]\n",
    "\n",
    "\n",
    "    training_loss, training_accuracy, test_loss, test_accuracy = calculate_loss_accuracy(train_x, train_y, test_x, test_y, weights, nn_layers, alpha,func)\n",
    "\n",
    "    training_loss_list.append(training_loss)\n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print((str(i+1)) + \"/\" + str(epochs) + \" completed\")\n",
    "\n",
    "  return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov_gd(train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func='cross_entropy'):\n",
    "    training_loss_list = []\n",
    "    training_accuracy_list = []\n",
    "    test_loss_list = []\n",
    "    test_accuracy_list = []\n",
    "\n",
    "    batch_x = np.array(np.array_split(train_x, n_batches))\n",
    "    batch_y = np.array(np.array_split(train_y, n_batches))\n",
    "\n",
    "    prev_weights = {}\n",
    "    look_ahead_w = {}\n",
    "\n",
    "    gamma = 0.9\n",
    "\n",
    "    for k, layer in enumerate(nn_layers):\n",
    "        prev_weights[\"w\" + str(k + 1)] = np.zeros(weights[\"w\" + str(k + 1)].shape)\n",
    "        prev_weights[\"b\" + str(k + 1)] = np.zeros(weights[\"b\" + str(k + 1)].shape)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for j in range(n_batches):\n",
    "\n",
    "            for k, layer in enumerate(nn_layers):\n",
    "                look_ahead_w[\"w\" + str(k + 1)] = weights[\"w\" + str(k + 1)] - gamma * prev_weights[\"w\" + str(k + 1)]\n",
    "                look_ahead_w[\"b\" + str(k + 1)] = weights[\"b\" + str(k + 1)] - gamma * prev_weights[\"b\" + str(k + 1)]\n",
    "\n",
    "            y_hat, layer_output = forward_prop(batch_x[j], look_ahead_w, nn_layers)\n",
    "            gradients = back_prop(y_hat, batch_y[j], layer_output, look_ahead_w, nn_layers, alpha,func)\n",
    "\n",
    "            for k, layer in enumerate(nn_layers):\n",
    "                prev_weights[\"w\" + str(k + 1)] = gamma * prev_weights[\"w\" + str(k + 1)] + eta * gradients[\n",
    "                    \"dw\" + str(k + 1)]\n",
    "                prev_weights[\"b\" + str(k + 1)] = gamma * prev_weights[\"b\" + str(k + 1)] + eta * gradients[\n",
    "                    \"db\" + str(k + 1)]\n",
    "\n",
    "                weights[\"w\" + str(k + 1)] -= prev_weights[\"w\" + str(k + 1)]\n",
    "                weights[\"b\" + str(k + 1)] -= prev_weights[\"b\" + str(k + 1)]\n",
    "\n",
    "        training_loss, training_accuracy, test_loss, test_accuracy = calculate_loss_accuracy(train_x,train_y,test_x, test_y,weights,nn_layers, alpha,func)\n",
    "\n",
    "        training_loss_list.append(training_loss)\n",
    "        training_accuracy_list.append(training_accuracy)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "        print((str(i + 1)) + \"/\" + str(epochs) + \" completed\")\n",
    "\n",
    "    return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop(train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func='cross_entropy'):\n",
    "\n",
    "  training_loss_list = []\n",
    "  training_accuracy_list = []\n",
    "  test_loss_list = []\n",
    "  test_accuracy_list = []\n",
    "\n",
    "  batch_x = np.array(np.array_split(train_x, n_batches))\n",
    "  batch_y = np.array(np.array_split(train_y, n_batches))\n",
    "\n",
    "  v = {}\n",
    "\n",
    "  beta = 0.9\n",
    "  epsilon = 1e-8\n",
    "\n",
    "  for k, layer in enumerate(nn_layers):\n",
    "          v[\"w\" + str(k+1)] = np.zeros(weights[\"w\" + str(k+1)].shape)\n",
    "          v[\"b\" + str(k+1)] = np.zeros(weights[\"b\" + str(k+1)].shape)\n",
    "\n",
    "  for i in range(epochs):\n",
    "    for j in range(n_batches):\n",
    "\n",
    "        y_hat, layer_output = forward_prop(batch_x[j], weights, nn_layers)\n",
    "        gradients = back_prop(y_hat, batch_y[j], layer_output, weights, nn_layers, alpha,func)\n",
    "\n",
    "        for k, layer in enumerate(nn_layers):\n",
    "          v[\"w\" + str(k+1)] = beta * v[\"w\" + str(k+1)] + (1-beta) * gradients[\"dw\" + str(k+1)]**2\n",
    "          v[\"b\" + str(k+1)] = beta * v[\"b\" + str(k+1)] + (1-beta) * gradients[\"db\" + str(k+1)]**2\n",
    "\n",
    "          weights[\"w\" + str(k+1)] -= eta * np.divide(gradients[\"dw\" + str(k+1)], np.sqrt(v[\"w\" + str(k+1)] + epsilon))\n",
    "          weights[\"b\" + str(k+1)] -= eta * np.divide(gradients[\"db\" + str(k+1)], np.sqrt(v[\"b\" + str(k+1)] + epsilon))\n",
    "\n",
    "\n",
    "    training_loss, training_accuracy, test_loss, test_accuracy = calculate_loss_accuracy(train_x, train_y, test_x, test_y, weights, nn_layers, alpha,func)\n",
    "\n",
    "    training_loss_list.append(training_loss)\n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print((str(i+1)) + \"/\" + str(epochs) + \" completed\")\n",
    "\n",
    "  return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func='cross_entropy'):\n",
    "\n",
    "  training_loss_list = []\n",
    "  training_accuracy_list = []\n",
    "  test_loss_list = []\n",
    "  test_accuracy_list = []\n",
    "\n",
    "  batch_x = np.array(np.array_split(train_x, n_batches))\n",
    "  batch_y = np.array(np.array_split(train_y, n_batches))\n",
    "\n",
    "  v = {}\n",
    "  v_hat = {}\n",
    "  m = {}\n",
    "  m_hat = {}\n",
    "\n",
    "  beta1 = 0.9\n",
    "  beta2 = 0.999\n",
    "  epsilon = 1e-8\n",
    "\n",
    "  for k, layer in enumerate(nn_layers):\n",
    "          v[\"w\" + str(k+1)] = np.zeros(weights[\"w\" + str(k+1)].shape)\n",
    "          v[\"b\" + str(k+1)] = np.zeros(weights[\"b\" + str(k+1)].shape)\n",
    "          m[\"w\" + str(k+1)] = np.zeros(weights[\"w\" + str(k+1)].shape)\n",
    "          m[\"b\" + str(k+1)] = np.zeros(weights[\"b\" + str(k+1)].shape)\n",
    "\n",
    "  t = 0\n",
    "\n",
    "  for i in range(epochs):\n",
    "    for j in range(n_batches):\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        y_hat, layer_output = forward_prop(batch_x[j], weights, nn_layers)\n",
    "        gradients = back_prop(y_hat, batch_y[j], layer_output, weights, nn_layers, alpha,func)\n",
    "\n",
    "        for k, layer in enumerate(nn_layers):\n",
    "          v[\"w\" + str(k+1)] = beta2 * v[\"w\" + str(k+1)] + (1-beta2) * gradients[\"dw\" + str(k+1)]**2\n",
    "          v[\"b\" + str(k+1)] = beta2 * v[\"b\" + str(k+1)] + (1-beta2) * gradients[\"db\" + str(k+1)]**2\n",
    "\n",
    "          m[\"w\" + str(k+1)] = beta1 * m[\"w\" + str(k+1)] + (1-beta1) * gradients[\"dw\" + str(k+1)]\n",
    "          m[\"b\" + str(k+1)] = beta1 * m[\"b\" + str(k+1)] + (1-beta1) * gradients[\"db\" + str(k+1)]\n",
    "\n",
    "          v_hat[\"w\" + str(k+1)] = np.divide(v[\"w\" + str(k+1)], (1-beta2**t))\n",
    "          v_hat[\"b\" + str(k+1)] = np.divide(v[\"b\" + str(k+1)], (1-beta2**t))\n",
    "\n",
    "          m_hat[\"w\" + str(k+1)] = np.divide(m[\"w\" + str(k+1)], (1-beta1**t))\n",
    "          m_hat[\"b\" + str(k+1)] = np.divide(m[\"b\" + str(k+1)], (1-beta1**t))\n",
    "\n",
    "          weights[\"w\" + str(k+1)] -= eta * np.divide(m_hat[\"w\" + str(k+1)], np.sqrt(v_hat[\"w\" + str(k+1)] + epsilon))\n",
    "          weights[\"b\" + str(k+1)] -= eta * np.divide(m_hat[\"b\" + str(k+1)], np.sqrt(v_hat[\"b\" + str(k+1)] + epsilon))\n",
    "\n",
    "\n",
    "    training_loss, training_accuracy, test_loss, test_accuracy = calculate_loss_accuracy(train_x, train_y, test_x, test_y, weights, nn_layers, alpha,func)\n",
    "\n",
    "    training_loss_list.append(training_loss)\n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print((str(i+1)) + \"/\" + str(epochs) + \" completed\")\n",
    "\n",
    "  return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nadam(train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func='cross_entropy'):\n",
    "    training_loss_list = []\n",
    "    training_accuracy_list = []\n",
    "    test_loss_list = []\n",
    "    test_accuracy_list = []\n",
    "\n",
    "    batch_x = np.array(np.array_split(train_x, n_batches))\n",
    "    batch_y = np.array(np.array_split(train_y, n_batches))\n",
    "\n",
    "    v = {}\n",
    "    v_hat = {}\n",
    "    m = {}\n",
    "    m_hat = {}\n",
    "\n",
    "    look_ahead_w = {}\n",
    "    look_ahead_m_hat = {}\n",
    "    look_ahead_v_hat = {}\n",
    "\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    for k, layer in enumerate(nn_layers):\n",
    "        v[\"w\" + str(k + 1)] = np.zeros(weights[\"w\" + str(k + 1)].shape)\n",
    "        v[\"b\" + str(k + 1)] = np.zeros(weights[\"b\" + str(k + 1)].shape)\n",
    "        m[\"w\" + str(k + 1)] = np.zeros(weights[\"w\" + str(k + 1)].shape)\n",
    "        m[\"b\" + str(k + 1)] = np.zeros(weights[\"b\" + str(k + 1)].shape)\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for j in range(n_batches):\n",
    "\n",
    "            t += 1\n",
    "\n",
    "            for k, layer in enumerate(nn_layers):\n",
    "                look_ahead_v_hat[\"w\" + str(k + 1)] = np.divide(beta2 * v[\"w\" + str(k + 1)], (1 - beta2 ** t))\n",
    "                look_ahead_v_hat[\"b\" + str(k + 1)] = np.divide(beta2 * v[\"b\" + str(k + 1)], (1 - beta2 ** t))\n",
    "\n",
    "                look_ahead_m_hat[\"w\" + str(k + 1)] = np.divide(beta1 * m[\"w\" + str(k + 1)], (1 - beta1 ** t))\n",
    "                look_ahead_m_hat[\"b\" + str(k + 1)] = np.divide(beta1 * m[\"b\" + str(k + 1)], (1 - beta1 ** t))\n",
    "\n",
    "                look_ahead_w[\"w\" + str(k + 1)] = weights[\"w\" + str(k + 1)] - eta * np.divide(\n",
    "                    look_ahead_m_hat[\"w\" + str(k + 1)], np.sqrt(look_ahead_v_hat[\"w\" + str(k + 1)] + epsilon))\n",
    "                look_ahead_w[\"b\" + str(k + 1)] = weights[\"b\" + str(k + 1)] - eta * np.divide(\n",
    "                    look_ahead_m_hat[\"b\" + str(k + 1)], np.sqrt(look_ahead_v_hat[\"b\" + str(k + 1)] + epsilon))\n",
    "\n",
    "            y_hat, layer_output = forward_prop(batch_x[j], look_ahead_w, nn_layers)\n",
    "            gradients = back_prop(y_hat, batch_y[j], layer_output, look_ahead_w, nn_layers, alpha,func)\n",
    "\n",
    "            for k, layer in enumerate(nn_layers):\n",
    "                v[\"w\" + str(k + 1)] = beta2 * v[\"w\" + str(k + 1)] + (1 - beta2) * gradients[\"dw\" + str(k + 1)] ** 2\n",
    "                v[\"b\" + str(k + 1)] = beta2 * v[\"b\" + str(k + 1)] + (1 - beta2) * gradients[\"db\" + str(k + 1)] ** 2\n",
    "\n",
    "                m[\"w\" + str(k + 1)] = beta1 * m[\"w\" + str(k + 1)] + (1 - beta1) * gradients[\"dw\" + str(k + 1)]\n",
    "                m[\"b\" + str(k + 1)] = beta1 * m[\"b\" + str(k + 1)] + (1 - beta1) * gradients[\"db\" + str(k + 1)]\n",
    "\n",
    "                v_hat[\"w\" + str(k + 1)] = np.divide(v[\"w\" + str(k + 1)], (1 - beta2 ** t))\n",
    "                v_hat[\"b\" + str(k + 1)] = np.divide(v[\"b\" + str(k + 1)], (1 - beta2 ** t))\n",
    "\n",
    "                m_hat[\"w\" + str(k + 1)] = np.divide(m[\"w\" + str(k + 1)], (1 - beta1 ** t))\n",
    "                m_hat[\"b\" + str(k + 1)] = np.divide(m[\"b\" + str(k + 1)], (1 - beta1 ** t))\n",
    "\n",
    "                weights[\"w\" + str(k + 1)] -= eta * np.divide(m_hat[\"w\" + str(k + 1)],\n",
    "                                                             np.sqrt(v_hat[\"w\" + str(k + 1)] + epsilon))\n",
    "                weights[\"b\" + str(k + 1)] -= eta * np.divide(m_hat[\"b\" + str(k + 1)],\n",
    "                                                             np.sqrt(v_hat[\"b\" + str(k + 1)] + epsilon))\n",
    "\n",
    "        training_loss, training_accuracy, test_loss, test_accuracy = calculate_loss_accuracy(train_x,train_y,test_x, test_y,weights,nn_layers, alpha,func)\n",
    "\n",
    "        training_loss_list.append(training_loss)\n",
    "        training_accuracy_list.append(training_accuracy)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "        print((str(i + 1)) + \"/\" + str(epochs) + \" completed\")\n",
    "\n",
    "    return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y, test_x, test_y, nn_layers, epochs, eta, batch_size, optimizer, weight_init, alpha,\n",
    "          func='cross_entropy'):\n",
    "    weights = init_layers(nn_layers, weight_init)\n",
    "\n",
    "    n_batches = len(train_x) // batch_size\n",
    "\n",
    "    if optimizer == \"gradient_descent\":\n",
    "        weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list = gradient_descent(\n",
    "            train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func)\n",
    "\n",
    "    elif optimizer == \"momentum_gradient_descent\":\n",
    "        weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list = momentum_gd(\n",
    "            train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func)\n",
    "\n",
    "    elif optimizer == \"nesterov_accelerated_gradient_descent\":\n",
    "        weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list = nesterov_gd(\n",
    "            train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func)\n",
    "\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list = rmsprop(\n",
    "            train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func)\n",
    "\n",
    "    elif optimizer == \"adam\":\n",
    "        weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list = adam(\n",
    "            train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func)\n",
    "\n",
    "    elif optimizer == \"nadam\":\n",
    "        weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list = nadam(\n",
    "            train_x, train_y, test_x, test_y, weights, nn_layers, eta, epochs, n_batches, alpha,func)\n",
    "\n",
    "    else:\n",
    "        return \"Error - Wrong Optimizer\"\n",
    "\n",
    "    return weights, training_loss_list, training_accuracy_list, test_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 completed\n",
      "2/10 completed\n",
      "3/10 completed\n",
      "4/10 completed\n",
      "5/10 completed\n",
      "6/10 completed\n",
      "7/10 completed\n",
      "8/10 completed\n",
      "9/10 completed\n",
      "10/10 completed\n"
     ]
    }
   ],
   "source": [
    "eta = config.learn_rate\n",
    "epochs = config.epochs\n",
    "batch_size = config.batch_size\n",
    "optimizer = config.optimizer\n",
    "weight_init = config.weight_init\n",
    "alpha = config.alpha\n",
    "\n",
    "# batch_size = 1 for stochastic and batch_size = len(train_x) for batch updates\n",
    "#available_optimizers = [\"gradient_descent\", \"momentum_gradient_descent\", \"nesterov_accelerated_gradient_descent\", \"rmsprop\", \"adam\", \"nadam\"]\n",
    "\n",
    "weights, train_loss, train_accuracy, test_loss, test_accuracy = train(train_x, train_y, test_x, test_y, nn_layers, epochs, eta, batch_size, optimizer, weight_init, alpha,func='cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimized weights\n",
    "with open('weights.pickle', 'wb') as handle:\n",
    "    pickle.dump(weights, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load previously saved weights\n",
    "with open('weights.pickle', 'rb') as handle:\n",
    "    weights = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36828835811388255,\n",
       " 0.3249797423326323,\n",
       " 0.3087537292946356,\n",
       " 0.30540125228797793,\n",
       " 0.2982898713687454,\n",
       " 0.28359473162178495,\n",
       " 0.25095979071028673,\n",
       " 0.25881762222274585,\n",
       " 0.25214937231774937,\n",
       " 0.24082334119071364]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.864,\n",
       " 0.8810666666666667,\n",
       " 0.8878,\n",
       " 0.8866666666666667,\n",
       " 0.8871333333333333,\n",
       " 0.8960666666666667,\n",
       " 0.9052333333333333,\n",
       " 0.9044666666666666,\n",
       " 0.9041333333333333,\n",
       " 0.9088833333333334]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 4, 'hidden_layer_size': 128, 'learn_rate': 0.001, 'batch_size': 16, 'epochs': 10, 'alpha': 0, 'optimizer': 'nadam', 'activation': 'relu', 'weight_init': 'random'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8508,\n",
       " 0.8602,\n",
       " 0.8665,\n",
       " 0.8656,\n",
       " 0.8651,\n",
       " 0.8728,\n",
       " 0.8828,\n",
       " 0.8793,\n",
       " 0.8764,\n",
       " 0.8762]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4131814313432518,\n",
       " 0.3808898160213578,\n",
       " 0.38123229654930535,\n",
       " 0.3853963410943291,\n",
       " 0.3847895721349928,\n",
       " 0.3797932195219869,\n",
       " 0.362277435188562,\n",
       " 0.3781911944795003,\n",
       " 0.3748973560956223,\n",
       " 0.36904045586753553]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "\n",
      "[[5402    5   62  117   20    4  353    0   37    0]\n",
      " [   5 5894    2   63   20    0    8    1    6    1]\n",
      " [  42    1 4570   72  790    1  504    0   20    0]\n",
      " [ 105   14   13 5559  243    0   52    0   14    0]\n",
      " [   1    3  244  132 5327    1  258    0   34    0]\n",
      " [   1    1    0    0    0 5907    0   76    0   15]\n",
      " [ 794    3  250  119  433    0 4343    0   58    0]\n",
      " [   0    0    0    0    0   20    0 5897    3   80]\n",
      " [   3    1    3    7   18    3   13    1 5951    0]\n",
      " [   0    0    0    0    0   22    0  293    2 5683]]\n",
      "\n",
      "\n",
      "Test Confusion Matrix\n",
      "\n",
      "[[862   1  15  24   6   1  81   0  10   0]\n",
      " [  3 970   1  16   6   0   4   0   0   0]\n",
      " [ 16   0 702  17 147   0 116   0   2   0]\n",
      " [ 23   7  12 884  49   0  16   0   9   0]\n",
      " [  1   0  64  32 840   0  57   0   6   0]\n",
      " [  0   0   0   0   0 954   0  34   1  11]\n",
      " [133   2  49  35  91   0 674   0  16   0]\n",
      " [  0   0   0   0   0   9   0 970   0  21]\n",
      " [  5   0   1   2   3   4   5   4 976   0]\n",
      " [  0   0   0   1   0   5   1  63   0 930]]\n"
     ]
    }
   ],
   "source": [
    "train_y_vec = np.argmax(train_y,axis=1)\n",
    "test_y_vec = np.argmax(test_y,axis=1)\n",
    "y_hat_train,layer_train_output = forward_prop(train_x, weights, nn_layers)\n",
    "y_hat_test,layer_test_output = forward_prop(test_x, weights, nn_layers)\n",
    "y_hat_train = np.argmax(y_hat_train,axis=1)\n",
    "y_hat_test = np.argmax(y_hat_test,axis=1)\n",
    "cm_train = confusion_matrix(train_y_vec,y_hat_train)\n",
    "cm_test = confusion_matrix(test_y_vec,y_hat_test)\n",
    "print('Training Confusion Matrix\\n')\n",
    "print(cm_train)\n",
    "print('\\n\\nTest Confusion Matrix\\n')\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD8CAYAAABErA6HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGS9JREFUeJzt3X2UXVV5x/Hvb2aIBBKSCIghSRusaSv2BTBCWlqKhIYXXQa7ZBW1JWVFp6tNK7Rdy8b2jyykdklfoLqs1pTEBqsgoCxTykIiiC9tCe9gYrAJgZIhQMCEBAgCM/fpH2cPvaT3bSb3nDn3zO/DOmvO3efl2ZfAkz377H22IgIzMyuPvomugJmZvZ4Ts5lZyTgxm5mVjBOzmVnJODGbmZWME7OZWck4MZuZlYwTs5lZyTgxm5mVzEDeAX5y1/WFTC2c9muXFBEGgD6psFj9ff2FxXp1ZLiwWEU56rAjCov17P59hcUq7r9AKHJu8PArTxz0V3v12e0dV/mQo95S5L/KjrnFbGZWMrm3mM3MClUbmegaHDQnZjOrlgp0yTkxm1mlRNQmugoHzYnZzKql5sRsZlYubjGbmZWMH/6ZmZXMZGgxS/p5YCkwh2ys+U5gfURsybluZmZjFhUYldFygomkPweuJZtodBdwd9q/RtLK/KtnZjZGtVrnW0m1azEvB94eEa/WF0q6AtgMfKrRRZIGgUGAz64cZPn7zuxCVc3MOjAJujJqwLHA/xxQPjsdaygiVgOrobh3ZZiZAZPi4d8lwG2StgI7UtlPAW8F/ijPipmZjUvVW8wRcYuknwVOJnv4J2AIuDsiev+vJTOrngo8/Gs7KiOy+Y13FlAXM7ODV+KHep3yOGYzq5Qq/DLvxGxm1VL1PmYzs57jrgwzs5Jxi9nMrGRGXm1/Tsk5MZtZtbgro72iVq9+acfthcQBmDrvjMJiVWEW00QqcuXqInk6bQvuyjAzKxm3mM3MSsaJ2cysXMIP/8zMSsZ9zGZmJeOuDDOzknGL2cysZNxiNjMrmQq0mFsuxmpm1nOGhzvf2pD0mKQfSHpA0j2p7I2SNkjamn7OSuWS9BlJ2yQ9JOmkuvssS+dvlbSsXdxxJ2ZJF433WjOz3ESt860z74qIEyJiYfq8ErgtIhYAt6XPAOcAC9I2CHweskQOrAJOIVsNatVoMm/mYFrMlzY7IGlQ0j2S7qnVXjyIEGZmY1Srdb6Nz1JgXdpfB5xXV351ZO4EZkqaDZwFbIiI3RGxB9gAnN0qQMs+ZkkPNTsEHNPsuvpVsgemzPG0fjMrTnf7mAO4VVIAX0i57ZiIeBIgIp6U9KZ07hz+b9FqyNZHndOivKl2D/+OIcv2ew4oF/Cfba41MyveGFrCkgbJuh1GrU7Jd9SpEbEzJd8Nkh5udbsGZdGivKl2ifkmYFpEPPD/aiDd0eZaM7PijaHFXP/bfZPjO9PPXZJuJOsjflrS7NRang3sSqcPAfPqLp8L7Ezlpx9QfkererXsY46I5RHx/SbHPtjqWjOzCdGlURmSDpc0fXQfWAJsAtYDoyMrlgHfSPvrgQvT6IxFwN7U5fFNYImkWemh35JU1pTHMZtZtUTXHmsdA9woCbJc+ZWIuEXS3cB1kpYDjwPnp/NvBs4FtgH7gYuy6sRuSZcBd6fzPhERu1sFdmI2s2rp0sy/iNgO/HKD8h8DixuUB7Ciyb3WAms7je3EbGbV4inZZmYlU4Ep2U7MZlYtI72/TmbuibnRAL48HDbvjMIWqNz3N+8pKBLMWnlzYbF+6Y3zC4v10I8fLSTOvOlHFRIHYMfzzxYWy1pwV0Z5eHqhmQFOzGZmpeM+ZjOzcola7//+7MRsZtXirgwzs5LxqAwzs5Jxi9nMrGScmM3MSqZ7LzGaMG2XlpL085IWS5p2QHnLpVHMzCZE/ktL5a5lYpb0UbJ3jf4xsEnS0rrDf51nxczMxqUWnW8l1a4r4yPAOyLiBUnzgRskzY+IT1PcbGszs85NglEZ/RHxAkBEPCbpdLLk/NO0SMz162j19c+gr+/wLlXXzKy1KHEXRafa9TE/JemE0Q8pSb8HOAr4xWYXRcTqiFgYEQudlM2sUJOgK+NC4HULY0XEMNm6Vl/IrVZmZuNV9XdlRMRQi2P/0f3qmJkdpBK3hDvlccxmVi3D1X/4Z2bWW6relWFm1nPclWFmVi5VGC7nxGxm1eIWs5lZyTgxt9ff1593CACGa8U9iT3iYzcVFuvF+/6lsFhvXvQHhcUqyhMv/Hiiq2BFmwRTss3MeorX/DMzK5sKJOa272M2M+spXX4fs6R+SfdLuil9Pk7SRklbJX1V0pRU/ob0eVs6Pr/uHh9P5T+SdFa7mE7MZlYt3X+J0cXAlrrPlwNXRsQCYA+wPJUvB/ZExFuBK9N5SDoeuAB4O3A28DlJLR++OTGbWbV0MTFLmgu8G7gqfRZwBnBDOmUdcF7aX5o+k44vTucvBa6NiJcj4lFgG3Byq7juYzazSomRrk4w+QfgY8D09PlI4Ln0lk2AIWBO2p8D7IDsLZyS9qbz5wB31t2z/pqG3GI2s2oZQ4tZ0qCke+q2wdHbSHoPsCsi7q27e6MFQqLNsVbXNOQWs5lVyliGy0XEamB1k8OnAu+VdC5wKHAEWQt6pqSB1GqeC+xM5w8B84AhSQPADGB3Xfmo+msa6mSV7JMlvTPtHy/pT1NFzczKp0t9zBHx8YiYGxHzyR7e3R4RHwK+Dbw/nbaMbMFqgPXpM+n47RERqfyCNGrjOGABcFer2C1bzJJWAecAA5I2AKcAdwArJZ0YEZ9s+c3MzIqW/zuM/hy4VtJfAfcDa1L5GuBLkraRtZQvAIiIzZKuA35ItiLUiohoOT2xXVfG+4ETgDcATwFzI2KfpL8FNgINE3P9YqwDA7Po75/W7ouamXVFDHc/M0fEHWSNUiJiOw1GVUTET4Dzm1z/SZrky0badWUMR8RIROwHHomIfSnIS7T4e6l+MVYnZTMrVG0MW0m1azG/IumwlJjfMVooaQal/lpmNllNhndlnBYRLwNEvG69lkP4v05uM7PyqECTsd0q2S83KX8WeDaXGpmZHYTJ0GI2M+stVW8xm5n1mtcmS/cwJ2Yzq5Rwi9nMrGScmM3MysUtZjOzknFi7kCRq1cXZfqUqYXFmvnODxcWa8+3/rqwWNPe9bFi4hT4Z7Xv5f2FxWr0Hsm89Nrgsxgp8t9OPtxiNrNKcYvZzKxkouYWs5lZqbjFbGZWMhFuMZuZlYpbzGZmJVPzqAwzs3Lxwz8zs5KpQmJuu0r2gSRdnUdFzMy6IaLzrazarZK9/sAi4F2SZgJExHvzqpiZ2XhUocXcritjLtmS21eRzcwUsBD4+1YX1a+Srf4Z9PUdfvA1NTPrQBWGy7XrylgI3Av8JbA3LeH9UkR8JyK+0+yi+lWynZTNrEgjI+p4K6t2a/7VgCslXZ9+Pt3uGjOziVSFFnNHSTYihoDzJb0b2JdvlczMxm8y9DG/TkT8O/DvOdXFzOyglXm0RafcLWFmlTLpWsxmZmU3Uhvz9IzS6f1vYGZWp1sTTCQdKukuSQ9K2izp0lR+nKSNkrZK+qqkKan8DenztnR8ft29Pp7KfyTprHbfwYnZzCqlFup4a+Nl4IyI+GXgBOBsSYuAy4ErI2IBsAdYns5fDuyJiLcCV6bzkHQ8cAHwduBs4HOS+lsFdmI2s0qJUMdb6/tERMQL6eMhaQvgDOCGVL4OOC/tL02fSccXS1IqvzYiXo6IR4FtwMmtYjsxm1mljKUrQ9KgpHvqtsH6e0nql/QAsAvYADwCPBcRw+mUIWBO2p8D7MjqEMPAXuDI+vIG1zTkh3/j8PwrL010FXJR1MrVAC8N3VFInKlzTy8kDkB/X3HtnJFaBd4Gn5MOuiheExGrgdUtjo8AJ6T3A90IvK3Raelno8DRorwpJ2Yzq5Q8RmVExHOS7gAWATMlDaRW8VxgZzptCJgHDEkaAGYAu+vKR9Vf05C7MsysUmIMWyuSjh59k6akqcCZwBbg28D702nLgG+k/fXpM+n47RERqfyCNGrjOGABcFer2G4xm1mljKUro43ZwLo0gqIPuC4ibpL0Q+BaSX8F3A+sSeevAb4kaRtZS/kCgIjYLOk6sjd1DgMrUhdJU07MZlYp3XqJUUQ8BJzYoHw7DUZVRMRPgPOb3OuTwCc7je3EbGaVUoXHok7MZlYp0XAQRG9xYjazShmeLO9jNjPrFZOuxSzp18g6vTdFxK35VMnMbPyq0MfcchyzpLvq9j8CfBaYDqyStDLnupmZjVmgjreyajfB5JC6/UHgNyPiUmAJ8KFmF9XPP6/VXuxCNc3MOlMbw1ZW7boy+iTNIkvgiohnACLiRUnDzS6qn38+MGVOBRZ6MbNeMVLilnCn2iXmGcC9ZC/hCElvjoinJE2j8Ys5zMwmVAVWlmqdmCNifpNDNeB9Xa+NmdlBqlWgzTiu4XIRsR94tMt1MTM7aFXoO/U4ZjOrlDI/1OuUE7OZVUpNk7Qrw8ysrFq+T7NHODGbWaVUflSGmVmvmbSjMsbihCPfkneI1zzw4+2FxJk+ZWohcQB+MvJqYbGOnDq9sFhFLZK6d+WvFxIHYManvldYrL4C+1Fr0VvjHHqrto1VpsVcVFI2s3JzV4aZWcl4uJyZWcmMuMVsZlYubjGbmZWME7OZWclUYMk/J2Yzqxa3mM3MSqYKU7Lbrfl3iqQj0v5USZdK+jdJl0uaUUwVzcw6V1PnW1m1W/NvLbA/7X+abEWTy1PZF3Osl5nZuFRhzb92ibkvIkbX9lsYEZdExPfTgqzFzbU2M+tQtxKzpHmSvi1pi6TNki5O5W+UtEHS1vRzViqXpM9I2ibpIUkn1d1rWTp/q6Rl7b5Du8S8SdJFaf9BSQtTkJ8Fmr7EoX6V7Gf2P9WuDmZmXRNj2NoYBv4sIt4GLAJWSDoeWAncFhELgNvSZ4BzgAVpGwQ+D1kiB1YBpwAnA6tGk3kz7RLzh4HfkPQIcDzwX5K2A/+cjjUUEasjYmFELDz6sDe3CWFm1j3d6mOOiCcj4r60/zywBZgDLAXWpdPWAeel/aXA1ZG5E5gpaTZwFrAhInZHxB5gA3B2q9jtFmPdC/yepOlkXRcDwFBEPN36K5mZTYw8RmVImg+cCGwEjomIJyFL3pLelE6bA+you2wolTUrb6qj4XLpb4sHOznXzGwi1cbw4k9Jg2TdDqNWR8TqA86ZBnwNuCQi9qn5K1cbHYgW5U15HLOZVcpYRlukJLy62XFJh5Al5S9HxNdT8dOSZqfW8mxgVyofAubVXT4X2JnKTz+g/I5W9WrXx2xm1lO69fBPWdN4DbAlIq6oO7QeGB1ZsQz4Rl35hWl0xiJgb+ry+CawRNKs9NBvSSpryi1mM6uULo5PPhX4XeAHkh5IZX8BfAq4TtJy4HHg/HTsZuBcYBvZXI+LACJit6TLgLvTeZ+IiN2tAjsxm1mlDKs7i0tFxPdp3D8MsLjB+QGsaHKvtWQT9jrixGxmleI1/8zMSqbMU607lXtiruIiqc+/8tJEVyEXT72wZ6Kr0HVFrlz90o7bC4s1dd4ZhcXq7+utMQJjGS5XVm4xm1ml9H5admI2s4pxV4aZWcmMVKDN7MRsZpXiFrOZWcmEW8xmZuXiFrOZWcl4uJyZWcn0flpuv0r2RyXNa3WOmVmZDBMdb2XVbkrPZcBGSd+T9IeSji6iUmZm4xVj+Kes2iXm7WQvdb4MeAfwQ0m3pBVfpze7qH4x1lrtxS5W18ystW6tkj2R2iXmiIhaRNwaEcuBY4HPkS0k2PQlGPWLsfb1Hd7F6pqZtVaFFnO7h3+vexdpRLxK9pb+9ZKm5lYrM7NxKnNLuFPtEvNvNzsQEdV8xZqZ9bSRKG9LuFMtE3NE/HdRFTEz6waPYzYzK5ky9x13yonZzCplMvQxm5n1FHdlmJmVjLsyzMxKpvKjMszMeo27MszsNUWuXP3SzuJW/5567K8XFqsb/PDPzKxk3MdsZlYy7sowMyuZqMDDv3ZvlzMz6ykjRMdbO5LWStolaVNd2RslbZC0Nf2clcol6TOStkl6SNJJddcsS+dvlbSsXVwnZjOrlBrR8daBfyF7zXG9lcBtEbEAuC19BjgHWJC2QeDzkCVyYBVwCnAysGo0mTfjxGxmlRIRHW8d3Ou7wO4DipcC69L+OuC8uvKrI3MnMFPSbOAsYENE7I6IPcAG/n+yfx0nZjOrlLG0mOtXW0rbYAchjomIJwHSzzel8jnAjrrzhlJZs/Km/PDPzCplLMPlImI1sLpLodWgLFqUN9Vulewpki6UdGb6/EFJn5W0QtIhHVfXzKwgIxEdb+P0dOqiIP3clcqHgHl1580FdrYob6pdV8YXgXcDF0v6EnA+sBF4J3BVZ9/BzKw4XX7418h6YHRkxTLgG3XlF6bRGYuAvamr45vAEkmz0kO/JamsqXZdGb8YEb8kaQB4Ajg2IkYk/SvwYLOLUj/NIID6Z+AFWc2sKN2cYCLpGuB04ChJQ2SjKz4FXCdpOfA4WYMV4GbgXGAbsB+4CCAidku6DLg7nfeJiDjwgeLrtEvMfZKmAIcDhwEzyJ5QvgFo2pVR328zMGVO74/2NrOe0c0JJhHxgSaHFjc4N4AVTe6zFljbadx2iXkN8DDQD/wlcL2k7cAi4NpOg5iZFaXyU7Ij4kpJX037OyVdDZwJ/HNE3FVEBc3MxmJSvMQoInbW7T8H3JBrjczMDsJI9P6LPz2O2cwqpQovMXJiNrNKqXwfs5lZr5kUfcxmZr2k5q4MM7NycYvZzKxkPCrDzF4z89DiXj1Q5MrVL26+vrBY3eCuDDOzknFXhplZybjFbGZWMm4xm5mVzEiMTHQVDpoTs5lViqdkm5mVjKdkm5mVjFvMZmYlMylGZUj6GeB9ZKu8DgNbgWsiYm/OdTMzG7MqjMpouUq2pI8C/wQcSrYy9lSyBP1fkk7PvXZmZmM0ErWOt7Jq12L+CHBCWhn7CuDmiDhd0hfIluw+sdFFXiXbzCbKZOljHgBGyFbGng4QEY9L8irZZlY6k6GP+Srgbkl3AqcBlwNIOhrYnXPdzMzGrPIt5oj4tKRvAW8DroiIh1P5M2SJ2sysVCbFOOaI2AxsLqAuZmYHrfItZjOzXlPm0RadcmI2s0qpwsO/luOYzcx6TUR0vLUj6WxJP5K0TdLKAqoPODGbWcXEGP5pRVI/8I/AOcDxwAckHV/AV3BiNrNq6WKL+WRgW0Rsj4hXgGuBpbl/AdzHbGYV08U+5jnAjrrPQ8Ap3bp5K7kn5uFXntB4rpM0mGYQ5qqoOI7VW7Gq+J2qHKveWHJO/esjktV1dW50n0KeLJa5K2Ow/Sk9FcexeitWFb9TlWONS0SsjoiFdVv9XyRDZC9tGzUX2FlEvcqcmM3MJtLdwAJJx0maAlwArC8isPuYzcwaiIhhSX8EfBPoB9ammdC5K3NiLqpvqsg+MMfqnVhV/E5VjpWLiLgZuLnouKrCvHIzsypxH7OZWcmULjEXNQVS0lpJuyRtyitGXax5kr4taYukzZIuzjHWoZLukvRginVpXrFSvH5J90u6Kec4j0n6gaQHJN2Tc6yZkm6Q9HD6M/uVnOL8XPo+o9s+SZfkFOtP0n8PmyRdI+nQPOKkWBenOJvz+j6VN5ZZMnlvZB3sjwBvAaYADwLH5xTrNOAkYFMB32s2cFLanw78d47fS8C0tH8IsBFYlON3+1PgK8BNOf87fAw4Ku8/qxRrHfDhtD8FmFlAzH7gKeCnc7j3HOBRYGr6fB3wezl9j18ANgGHkT3D+hawoIg/typtZWsxFzYFMiK+S0GrsETEkxFxX9p/HthC9j9LHrEiIl5IHw9JWy4PEiTNBd5NttJNJUg6guwv7TUAEfFKRDxXQOjFwCMR8T853X8AmCppgCxp5jUe923AnRGxPyKGge8A78spVmWVLTE3mgKZSwKbKJLmky1iuzHHGP2SHgB2ARsiIq9Y/wB8DCjiBbgB3Crp3jRbKy9vAZ4Bvpi6aK6SVMRqwhcA1+Rx44h4Avg74HHgSWBvRNyaRyyy1vJpko6UdBhwLq+fpGEdKFtinrApkEWQNA34GnBJROzLK05EjETECWQzlU6W9AvdjiHpPcCuiLi32/du4tSIOInsTV8rJOW1tNkAWRfX5yPiROBFINfXPabJC+8Frs/p/rPIfvM8DjgWOFzS7+QRKyK2kK0NugG4haw7cjiPWFVWtsQ8YVMg85ZWFf8a8OWI+HoRMdOv4HcAZ+dw+1OB90p6jKzL6QxJ/5pDHAAiYmf6uQu4kazbKw9DwFDdbxk3kCXqPJ0D3BcRT+d0/zOBRyPimYh4Ffg68Ks5xSIi1kTESRFxGll34da8YlVV2RLzhE2BzJMkkfVZbomIK3KOdbSkmWl/Ktn/lA93O05EfDwi5kbEfLI/p9sjIpdWmKTDJU0f3QeWkP3K3HUR8RSwQ9LPpaLFwA/ziFXnA+TUjZE8DiySdFj6b3Ex2XOOXEh6U/r5U8Bvke93q6RSzfyLAqdASroGOB04StIQsCoi1uQRi6x1+bvAD1LfL8BfRDarqNtmA+vSS777gOsiItehbAU4BrgxyykMAF+JiFtyjPfHwJdT42A7cFFegVI/7G8Cv59XjIjYKOkG4D6yboX7yXdW3tckHQm8CqyIiD05xqokz/wzMyuZsnVlmJlNek7MZmYl48RsZlYyTsxmZiXjxGxmVjJOzGZmJePEbGZWMk7MZmYl879nEkUJXllAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training Confusion Matrix\\n')\n",
    "ax_train = sns.heatmap(cm_train)\n",
    "wandb.log({\"Confusion Matrix Train\": wandb.Image(ax_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Test Confusion Matrix\\n')\n",
    "ax_test = sns.heatmap(cm_test)\n",
    "wandb.log({\"Confusion Matrix Test\": wandb.Image(ax_test)})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS6910_Assignment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
